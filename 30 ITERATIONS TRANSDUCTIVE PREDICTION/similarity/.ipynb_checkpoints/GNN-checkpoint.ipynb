{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3064943",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jayant\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Jayant\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\Jayant\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n",
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jayant\\Anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\__init__.py\n",
      "src2665\n",
      "dest2665\n",
      "C:\\Users\\Jayant\\Anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\__init__.py\n"
     ]
    },
    {
     "ename": "DGLError",
     "evalue": "Expect number of features to match number of nodes (len(u)). Got 1038 and 1034 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDGLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_588\\4065317275.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdgl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtrain_gsData\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtest_gsData\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mhetDotProduct\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHeteroDotProductPredictor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Minor project MSC\\30 ITERATIONS TRANSDUCTIVE PREDICTION\\similarity\\test_gsData.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturn_features_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m \u001b[0mtest_hetero_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'judgement'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'feature'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\dgl\\view.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, val)\u001b[0m\n\u001b[0;32m     79\u001b[0m                 \u001b[1;34m'The HeteroNodeDataView has only one node type. '\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m                 \u001b[1;34m'please pass a tensor directly'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_n_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ntid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__delitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\dgl\\heterograph.py\u001b[0m in \u001b[0;36m_set_n_repr\u001b[1;34m(self, ntid, u, data)\u001b[0m\n\u001b[0;32m   3991\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnfeats\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnum_nodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3992\u001b[0m                 raise DGLError('Expect number of features to match number of nodes (len(u)).'\n\u001b[1;32m-> 3993\u001b[1;33m                                ' Got %d and %d instead.' % (nfeats, num_nodes))\n\u001b[0m\u001b[0;32m   3994\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3995\u001b[0m                 raise DGLError('Cannot assign node feature \"{}\" on device {} to a graph on'\n",
      "\u001b[1;31mDGLError\u001b[0m: Expect number of features to match number of nodes (len(u)). Got 1038 and 1034 instead."
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from model import Model\n",
    "#import pygraphviz as pgv\n",
    "import dgl.nn as dglnn\n",
    "import dgl.function as fn\n",
    "from train_gsData import *\n",
    "from test_gsData import *\n",
    "from hetDotProduct import HeteroDotProductPredictor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from rgcnClass import RGCN\n",
    "\n",
    "\n",
    "sampling_rate = 1\n",
    "\n",
    "global feature\n",
    "\n",
    "\n",
    "res_text = open(\"res.txt\",\"w\")\n",
    "\n",
    "\n",
    "def construct_negative_graph(graph, k, etype):\n",
    "    utype, _, vtype = etype\n",
    "    src, dst = graph.edges(etype=etype)\n",
    "    torch.random.manual_seed(1)\n",
    "\n",
    "    neg_src = src.repeat_interleave(k)\n",
    "    neg_dst = torch.randint(0, graph.num_nodes(vtype), (len(src) * k,))\n",
    "    return dgl.heterograph(\n",
    "        {etype: (neg_src, neg_dst)},\n",
    "        num_nodes_dict={ntype: graph.num_nodes(ntype) for ntype in graph.ntypes})\n",
    "\n",
    "\n",
    "def compute_loss(pos_score, neg_score):\n",
    "    # Margin loss\n",
    "    n_edges = pos_score.shape[0]\n",
    "    return (1 - pos_score.unsqueeze(1) + neg_score.view(n_edges, -1)).clamp(min=0).mean()\n",
    "\n",
    "\n",
    "def manual_auc(scores, labels):\n",
    "    s = []\n",
    "    p = []\n",
    "    for i in range(len(scores)):\n",
    "        s.append((scores[i])[0])\n",
    "    l = labels.tolist()\n",
    "    '''print(\"SCORES LENGTH: \",len(s))\n",
    "    print(s)\n",
    "    print(\"LABELS LENGTH: \",len(l))\n",
    "    print(l)'''\n",
    "    I = 0\n",
    "    for i in range(len(l)):\n",
    "        if l[i] == 0:\n",
    "            I = i\n",
    "            break\n",
    "    D = I * sampling_rate * I\n",
    "    np = I\n",
    "    nn = sampling_rate * I\n",
    "    counter = 0\n",
    "    for i in range(np):\n",
    "        percent = 0\n",
    "        for j in range(np, np + nn):\n",
    "            # print(\"j = \",j)\n",
    "            if s[i] > s[j]:\n",
    "                percent = percent + 1\n",
    "                counter = counter + 1\n",
    "        # print(\"---------- Positive sample is greater than \",percent/nn,\" number of negative samples\")\n",
    "        p.append(percent / nn)\n",
    "        percent = 0\n",
    "    # print(\"AUC MANUAL: \",counter/D)\n",
    "    return p\n",
    "\n",
    "\n",
    "def compute_auc(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
    "    p = manual_auc(scores, labels)\n",
    "    return roc_auc_score(labels, scores), p\n",
    "\n",
    "\n",
    "score = 0\n",
    "\n",
    "train = train_hetero_graph\n",
    "test = test_hetero_graph\n",
    "\n",
    "#for j in [\"NER_LAW\",\"LAWPOINTS\",\"DOMAIN_EXPERT\",\"BERT\"]:\n",
    "for j in [\"BERT\"]:\n",
    "    feature = j\n",
    "\n",
    "    ft = open(\"feat.txt\",\"w\")\n",
    "    print(\"writing!!!\")\n",
    "    ft.write(str(feature))\n",
    "    ft.close()\n",
    "    for epochs in [400,600,800]:\n",
    "\n",
    "        input_layer_nodes = 0\n",
    "        hidden_layer_nodes = 0\n",
    "        if feature == \"NER_LAW\":\n",
    "            input_layer_nodes = 28\n",
    "            hidden_layer_nodes = 18\n",
    "        elif feature == \"LAWPOINTS\":\n",
    "            input_layer_nodes = 14\n",
    "            hidden_layer_nodes = 9\n",
    "        elif feature == \"DOMAIN_EXPERT\":\n",
    "            input_layer_nodes = 85\n",
    "            hidden_layer_nodes = 56\n",
    "        else:\n",
    "            input_layer_nodes = 768\n",
    "            hidden_layer_nodes = 520\n",
    "\n",
    "\n",
    "        train_neg = construct_negative_graph(train, sampling_rate, ('judgement', 'similarTo', 'judgement'))\n",
    "        test_neg = construct_negative_graph(test, sampling_rate, ('judgement', 'similarTo', 'judgement'))\n",
    "        print(train.etypes)\n",
    "        model = Model(input_layer_nodes, hidden_layer_nodes, 2, train.etypes)\n",
    "        judgement_feats = train.nodes['judgement'].data['feature']\n",
    "        test_judgement_feats = test.nodes['judgement'].data['feature']\n",
    "        node_features = {'judgement': judgement_feats}  # , 'court': court_feats}\n",
    "        test_node_features = {'judgement': test_judgement_feats}\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "        pred = HeteroDotProductPredictor()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            h = model(train, train_neg, node_features, etype='similarTo')\n",
    "            pos_score = pred(train, h, etype='similarTo')\n",
    "            # print(len(pos_score))\n",
    "            neg_score = pred(train_neg, h, etype='similarTo')\n",
    "            # print(len(neg_score))\n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            loss = compute_loss(pos_score, neg_score)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            print('In epoch {}'.format(epoch))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pos_score = pred(test, h, etype='similarTo')\n",
    "            neg_score = pred(test_neg, h, etype='similarTo')\n",
    "            # node_embeddings = model.sage(test,test_node_features)\n",
    "            # torch.save(node_embeddings , 'similarity_node_embeddings.pt')\n",
    "            score, p = compute_auc(pos_score, neg_score)\n",
    "            # score contains the AUC of predefined function\n",
    "            # p contains the AUC computed by manual AUC\n",
    "            print('AUC', score)\n",
    "            index = []\n",
    "            neg_index = []\n",
    "            scores = []\n",
    "            neg_scores = []\n",
    "            for i in range(len(p)):\n",
    "                if p[i] > sum(p) / len(p):\n",
    "                    index.append(i)\n",
    "                    scores.append(p[i])\n",
    "                else:\n",
    "                    neg_index.append(i)\n",
    "                    neg_scores.append(p[i])\n",
    "            # print(\"INDICES: \",index)\n",
    "            # print(\"SCORES: \",scores)\n",
    "            data = pd.read_csv(\"input/TEST_SET_SAMPLED.csv\")\n",
    "            predicted = pd.DataFrame(columns=['SUBJECT', 'RELATION', 'OBJECT', 'SCORE'])\n",
    "            not_predicted = pd.DataFrame(columns=['SUBJECT', 'RELATION', 'OBJECT', 'SCORE'])\n",
    "            print(\"-------- Predicted Edges ---------\")\n",
    "            for i in range(len(index)):\n",
    "                print(\"-------------- POSITIVE SAMPLES\")\n",
    "                print(data.loc[index[i], :])\n",
    "                predicted.loc[i, 'SUBJECT'] = data.loc[index[i], 'SUBJECT']\n",
    "                predicted.loc[i, 'RELATION'] = data.loc[index[i], 'RELATION']\n",
    "                predicted.loc[i, 'OBJECT'] = data.loc[index[i], 'OBJECT']\n",
    "                predicted.loc[i, 'SCORE'] = scores[i]\n",
    "            for i in range(len(neg_index)):\n",
    "                print(\"--------------- NEGATIVE SAMPLES\")\n",
    "                print(data.loc[neg_index[i], :])\n",
    "                not_predicted.loc[i, 'SUBJECT'] = data.loc[neg_index[i], 'SUBJECT']\n",
    "                not_predicted.loc[i, 'RELATION'] = data.loc[neg_index[i], 'RELATION']\n",
    "                not_predicted.loc[i, 'OBJECT'] = data.loc[neg_index[i], 'OBJECT']\n",
    "                not_predicted.loc[i, 'SCORE'] = neg_scores[i]\n",
    "            predicted = predicted.drop_duplicates().reset_index(drop=True)\n",
    "            not_predicted = not_predicted.drop_duplicates().reset_index(drop=True)\n",
    "            predicted.to_csv(\"output/predicted_results.csv\", index=False)  # remove NEG later !!!!\n",
    "            not_predicted.to_csv(\"output/not_predicted_results.csv\", index=False)  # remove NEG later !!!\n",
    "\n",
    "            res_text.write(feature)\n",
    "            res_text.write(\"\\t\")\n",
    "            res_text.write(str(epochs))\n",
    "            res_text.write(\"\\t\")\n",
    "            res_text.write(str(sampling_rate))\n",
    "            res_text.write(\"\\t\")\n",
    "            res_text.write(str(score))\n",
    "            res_text.write(\"\\n\")\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "res_text.close()\n",
    "\n",
    "# Flow of the program\n",
    "# \n",
    "# Input: \n",
    "# 1. OE_LABELS(csv file) : contains features of the nodes\n",
    "# 2. MAPPING.json : maps the document ids to node ids\n",
    "# 3. TRAIN_SET(csv) : contains data in triples format where each row indicates an edge (docid,similarTo,docid)\n",
    "# 4. TEST_SET(csv) : contains data in triples format where each row indicates an edge (docid,similarTo,docid)\n",
    "# \n",
    "# Flow(as understood)\n",
    "# 1. Create a heterograph of train set\n",
    "# 2. Create a heterograph of test set\n",
    "# 3. Perform negative sampling in both the graphs\n",
    "# 4. Initialize RGCN model and pass parameters\n",
    "# 5. Train the model on using the train graph with negative edges as well\n",
    "# 6. Test the model using the TEST_SET\n",
    "# 7. Compute AUC score\n",
    "# 8. Compute the probabilities of similarity between two nodes in an edge\n",
    "# 9. Parse this probability array\n",
    "#     if prob. is greater than average(prob.)\n",
    "#         keep in predicted results\n",
    "#     else\n",
    "#         keep in non predicted results\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d2468d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
